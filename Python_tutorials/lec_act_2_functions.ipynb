{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lec_act_2_functions.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture goals\n",
    "\n",
    "1. (more) Dictionaries for data encapsulation\n",
    "2. Functions for functionality encapsulation\n",
    "\n",
    "Resources\n",
    "- Slides: https://docs.google.com/presentation/d/1ykwwcQ0onMvAjUxfJmKl9tbo-rJPdB5pRwDEmpDsd-g/edit?usp=sharing\n",
    "\n",
    "\n",
    "## Functions: \n",
    "Functions enable encapsulation of, well, functionality.\n",
    "\n",
    "They're also a useful mental tool for organizing and structuring your thoughts on how to solve a given problem\n",
    "1. Clearly define a bit of code that takes in some inputs, does some computation, then outputs some data\n",
    "2. Makes it easier to test that code with different inputs\n",
    "3. Practicalities: Prevents one of the most common sources of errors - re-using variable names\n",
    "\n",
    "It's almost never wrong to encapsulate a bit of code in a function. It can slow down (a tiny bit) computation time, but can greatly reduce debugging time, so it's usually worth it.\n",
    "\n",
    "Python's function syntax is beautifully designed to make it easy to set default values for parameters and pass back as much data as you want. We'll see more of that later; for this assignment we'll use the power of dictionaries to pass back \"labeled\" data.\n",
    "\n",
    "In this lecture activity you're essentially going to copy over the code you did in the previous lecture activity, right-shift it to place it in the function, replace the **test_** variable name with the input parameter to the function, then add a return to return the answer. This is a pretty common approach for turning code into a function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access all numpy functions as np.\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "## Question 1: Stats on a list\n",
    "\n",
    "### Calculate stats on a list\n",
    "\n",
    "TODO: in calc_stats_from_list function \n",
    "- Calculate the mean of the negative and positive values\n",
    "- Count the total number of negative/positive values\n",
    "- Store the values in a dictionary\n",
    "\n",
    "This function calculates the given stats from the list that is passed in. There is test code below this function.\n",
    "\n",
    "TODO: \n",
    " - Step 1 - copy your code from lecture activity 1 into the function. Right shift it so it is indented properly\n",
    " - Step 2 - change **test_list_one** to be **in_list** - the input parameter of the function\n",
    " - Step 3 - return the dictionary **dict_save_stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def calc_stats_from_list(in_list):\n",
    "    \"\"\" Calculate mean of positive numbers, mean of negatives numbers\n",
    "    Separate the list into positive and negative numbers. Calculate the mean of each. Return those means, along with\n",
    "     how many positive/negative numbers there were\n",
    "    @param in_list : any list type\n",
    "    @return - A dictionary with the desired stats\"\"\"\n",
    "\n",
    "    # These are the stats we're calculating. This is more elegant/useful than creating four variables - it keeps all\n",
    "    #  of the values in the same place and assigns a meaningful label (key) to them\n",
    "    dict_save_stats = {\"Mean positive\": 0.0, \"Mean negative\": -0.0, \"Count positive\": 0, \"Count negative\": 0}\n",
    "\n",
    "    # TODO: \n",
    "    #   Copy your code from lecture activity 1 here. Don't forget to change the name of test_list_one to be in_list\n",
    "    ...\n",
    "    # TODO Do the return here\n",
    "    return ...    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Test data\n",
    "test_list_one = [-0.9, -0.2, 1.0 / 3.0, 2.0 / 3.0, 3.0 / 3.0, 4.0 / 3.0, 5.0 / 3.0]\n",
    "test_list_res = calc_stats_from_list(test_list_one)\n",
    "\n",
    "b_tests_passed = True\n",
    "if not np.isclose(test_list_res[\"Mean positive\"], 3.0 / 3.0):\n",
    "    b_tests_passed = False\n",
    "    print(f\"Mean positive is not correct, should be {3.0/3.0}, got {test_list_res['Mean positive']}\")\n",
    "\n",
    "if not np.isclose(test_list_res[\"Mean negative\"], -0.55):\n",
    "    b_tests_passed = False\n",
    "    print(f\"Mean negative is not correct, should be -0.55, got {test_list_res['Mean negative']}\")\n",
    "\n",
    "if test_list_res[\"Count positive\"] != 5:\n",
    "    b_tests_passed = False\n",
    "    print(f\"Count positive numbers, should be 3, got {test_list_res['Count positive']}\")\n",
    "\n",
    "if test_list_res[\"Count negative\"] != 2:\n",
    "    b_tests_passed = False\n",
    "    print(f\"Count positive numbers, should be 2, got {test_list_res['Count negative']}\")\n",
    "\n",
    "if b_tests_passed:\n",
    "    print(\"All array tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# This is an example of what the autograder tests are doing\n",
    "res = calc_stats_from_list([-1, 2, -3, 4, -5])\n",
    "assert np.isclose(res[\"Mean positive\"], 3.0)\n",
    "\n",
    "# Remember that if you are printing anything out in calc_stats_from_list then the autograder will fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "# Question 2: Doing it again with a numpy array\n",
    "\n",
    "## Fill in calc_stats_from_nparray\n",
    "\n",
    "For this function, assume the input is a numpy array.\n",
    "\n",
    "TODO: Same as the previous question, but this time copy in the numpy array code you wrote in lecture activity 1. Again:\n",
    "- NO **if** statements or **for** loops - do this all with numpy operations\n",
    "\n",
    "As before, test code is below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def calc_stats_from_nparray(in_nparray):\n",
    "    \"\"\" Calculate mean of positive numbers, mean of negatives numbers\n",
    "    Separate the list into positive and negative numbers. Calculate the mean of each. Return those means, along with\n",
    "     how many positive/negative numbers there were\n",
    "    @param in_nparray : numpy array\n",
    "    @return - A dictionary with the desired stats\"\"\"\n",
    "\n",
    "    # TODO: Copy in the code, change the numpy array name to be the input to this function, and return the dictionary\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "test_nparray_one = np.array(test_list_one)  # Convert the previous test list to a numpy array\n",
    "test_list_res = calc_stats_from_nparray(test_nparray_one)\n",
    "\n",
    "b_tests_passed = True\n",
    "if not np.isclose(test_list_res[\"Mean positive\"], 3.0 / 3.0):\n",
    "    b_tests_passed = False\n",
    "    print(f\"Mean positive is not correct, should be {3.0/3.0}, got {test_list_res['Mean positive']}\")\n",
    "\n",
    "if not np.isclose(test_list_res[\"Mean negative\"], -0.55):\n",
    "    b_tests_passed = False\n",
    "    print(f\"Mean negative is not correct, should be -0.55, got {test_list_res['Mean negative']}\")\n",
    "\n",
    "if test_list_res[\"Count positive\"] != 5:\n",
    "    b_tests_passed = False\n",
    "    print(f\"Count positive numbers, should be 5, got {test_list_res['Count positive']}\")\n",
    "\n",
    "if test_list_res[\"Count negative\"] != 2:\n",
    "    b_tests_passed = False\n",
    "    print(f\"Count positive numbers, should be 2, got {test_list_res['Count negative']}\")\n",
    "\n",
    "if b_tests_passed:\n",
    "    print(\"All numpy array tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"nparray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "## Encapsulating data manipulation \n",
    "\n",
    "In the next few problems we'll encapsulate what you did in lecture activity 1 in a function and return the information in a dictionary. \n",
    "\n",
    "The first part (this problem) is to take the data creation code that made **my_test_data** and encapsulate it into a function\n",
    "\n",
    "The second part (next problem) extracts, eg, all of the x data, and return it in a dictionary\n",
    "\n",
    "The third part (final problem) uses those functions to create a dictionary with the desired information, using your **calc_stats_from_nparray** from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Making a data set to practice with before lab/homework\n",
    "#  From lecture activity 2\n",
    "#  Create data that consists of x, y, z data for t time steps for s samples\n",
    "#    x is time data (linspace from start to stop)\n",
    "#    y and z are uniform random sampling\n",
    "#    Ranges are given for the x, y, and z data\n",
    "#  The last column is 1 if the sample is good, 0 if it is bad. Every other sample is good\n",
    "#  The data is stored in a s x [3 * t + 1] array\n",
    "#  Each row (one row for each sample) looks like this\n",
    "#    x0 y0 z0 x1 y1 z1 .... x9 y9 z9 1 or 0\n",
    "def make_xyz_time_data(n_samples=5, n_time_steps=10, x_data_range=(0, 1), y_data_range=(-1, 0), z_data_range=(10, 20)):\n",
    "    \"\"\" Make some fake data to play with, same format as the last problem in lecture activity 1\n",
    "    @param n_samples - number of samples (rows)\n",
    "    @param n_time_steps - number of time steps (will be 3 * n_time_steps + 1 columns)\n",
    "    @param x_data_range - start and stop values for x\n",
    "    @param y_data_range - min and max values for y\n",
    "    @param y_data_range - min and max values for z\n",
    "    @return a n_samples * (3*n_time_steps + 1) numpy array\"\"\"\n",
    "\n",
    "    \n",
    "    # Make space for all of the data and fill it with zeros\n",
    "    #   zeros takes a tuple with the data sizes - in this case we are making a 2 dimensional array\n",
    "    #   with 5 columns (one for each sample) and 10 x,y,z value (30 total) and one extra column for the good/bad\n",
    "    my_test_data = np.zeros((5, 3 * 10 + 1))\n",
    "\n",
    "    # Fill in whether or not the sample is good. Every other one is good, the others are bad\n",
    "    # Since zero is bad - and the array is all zeros - just set every other row, last column\n",
    "    #   The -1 picks the last column, the 0::2 picks every other row\n",
    "    #   Note: The left hand side has 3 elements, the right a single number - numpy interprets this to mean\n",
    "    #     set all of those values to the single number\n",
    "    my_test_data[0::2, -1] = 1\n",
    "\n",
    "    # Fill in the x values for each sample with 0, 0.1... 1.0\n",
    "    #  np.linspace() generates uniformly-spaced samples from start to stop\n",
    "    #    You can assign values to specific parameters by name if you want\n",
    "    #    This would be the same as np.linspace(0, 1.0, 10)\n",
    "    # In this case, the array on the left hand side is 5 x 10, so we're going to use a loop to set each row\n",
    "    #  to 0, 0.1 etc. one row at a time\n",
    "    # shape is the size of the array; we want the number of rows so use .shape[0]\n",
    "    x_data_for_one_row = np.linspace(start=0, stop=1.0, num=10)\n",
    "    for r in range(0, my_test_data.shape[0]):\n",
    "        # loop through each row r\n",
    "        # Fill in column 0 to one before the end (don't overwrite the good/bad), skipping every 3\n",
    "        my_test_data[r, 0:-2:3] = x_data_for_one_row\n",
    "\n",
    "    # Fill in the y values for each sample with random values\n",
    "    #  np.random.uniform() generates random samples between the two values; unlike linsapce, you can set the size\n",
    "    #   of the numpy array it returns. \n",
    "    # The left side is all rows (5 - :) and every 3rd column starting at 1\n",
    "    y_data_for_all_rows = np.random.uniform(-1.0, 0.0, size=(5, 10))\n",
    "    my_test_data[:, 1::3] = y_data_for_all_rows\n",
    "\n",
    "    # Now the z values - notice that we start at column 2 instead of 1\n",
    "    my_test_data[:, 2::3] = np.random.uniform(10.0, 20.0, size=(5, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Test 1 - this should work as soon as you fix the return statement\n",
    "# Uses default paramters, which were the same as the lecture activity 1 code\n",
    "#   Reminder to re-execute the cell above once you've made a change\n",
    "my_test_data_check1 = make_xyz_time_data()\n",
    "\n",
    "# Check number of samples/rows is 5\n",
    "assert my_test_data_check1.shape[0] == 5\n",
    "\n",
    "# Check number of columns is 10 * 3 + 1\n",
    "assert my_test_data_check1.shape[1] == 10 * 3 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Test 2 - this should work once you replace the hard-wired 5's and 10's (number of samples and number of time steps) with the \n",
    "#   input variables n_samples and n_time_steps\n",
    "#  If you get an array dimensions mis-match error you probably missed replacing a 5 or a 10\n",
    "#   Reminder to re-execute the function cell when you've made a change\n",
    "\n",
    "my_test_data_check2 = make_xyz_time_data(n_samples=7, n_time_steps=13)\n",
    "\n",
    "# Check size of numpy array\n",
    "assert my_test_data_check2.shape[0] == 7\n",
    "assert my_test_data_check2.shape[1] == 13 * 3 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Test 3 - Changge the data creation ranges (the lines that actually make the x, y, z data) to use the input ranges\n",
    "#  This *should* just be finding the right place to replace, eg, 0 with x_data_range[0] and 1 with x_data_range[1]\n",
    "\n",
    "my_test_data_check3 = make_xyz_time_data(n_samples=10, n_time_steps=15, x_data_range=(10, 100), y_data_range=(-1, 2), z_data_range=(1.0, 3.0))\n",
    "\n",
    "# Check that x range for all samples starts at 10 and ends at 100\n",
    "assert np.all(np.isclose(my_test_data_check3[:, 0], 10.0))\n",
    "assert np.all(np.isclose(my_test_data_check3[:, -4], 100.0)) \n",
    "\n",
    "# Check that all y data is between -1 and 2\n",
    "n_all_data = 15 * 3 \n",
    "assert np.all(my_test_data_check3[:, 1:n_all_data:3] >= -1.0)\n",
    "assert np.all(my_test_data_check3[:, 1:n_all_data:3] <= 2.0)\n",
    "\n",
    "assert np.isclose(np.min(my_test_data_check3[:, 1:n_all_data:3]), -1.0, atol=0.1 )\n",
    "assert np.isclose(np.max(my_test_data_check3[:, 1:n_all_data:3]), 2.0, atol=0.1 )\n",
    "# TODO Check that all z data is between 1 and 3\n",
    "\n",
    "# Check that every value in the last column is either a 1 or a 0\n",
    "# TODO Write this test yourself. It's one of the autograder checks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"create_data_function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "### Data slice\n",
    "\n",
    "This is very close to the data slice you did at the end of lab 1. **n_total_dims** will be 3 for our test data (x,y,z), but the function should be able to work with data that has, for example, 4 repeating dimensions (w,x,y,z). \n",
    "\n",
    "TODO: \n",
    "- Step 1a: Use the scratch cell to create each of the x y z slices, using my_test_data_check1, which you know has 10 time steps\n",
    "- Step 1b: Check that the dimensions of each array that you create are correct (should be 5x10 for each of them)\n",
    "- Step 2a: Now replace any hard-wired numbers (eg, 0, 1,2 3, 10) with the appropriate variable (start_index, n_time_steps, n_total_dims)\n",
    "-   At this point you should have 3 slices that all look exactly the same\n",
    "- Step 2b: Check that you still get the same answer\n",
    "- Step 3b: Change every my_test_data_check1 to my_test_data_check2 (or 3) and see if it all still works correctly\n",
    "- Step 4: Copy your slice into the function, change my_test_data_check to all_data, and return the slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# SCRATCH CELL\n",
    "# Try writing the slice here for each of x, y, and z. \n",
    "#   HINT: The code in the previous problem already has a slice that gets out just the y, or z data for testing purposes...\n",
    "# The only tricky part is the x data; remember that you don't want to get the last column... if your x slice is 5x11, remember\n",
    "#   that you don't want the last column\n",
    "\n",
    "n_total_dims = 3\n",
    "# Rember we used different numbers of time steps - you can set this directly OR set it from my_test_data_checkX.shape[1]\n",
    "n_time_steps = ...\n",
    "\n",
    "start_index = ...\n",
    "my_x_slice = ...\n",
    "\n",
    "start_index = ...\n",
    "my_y_slice = ...\n",
    "\n",
    "start_index = ...\n",
    "my_z_slice = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def get_single_channel(all_data, start_index, n_total_dims, n_time_steps):\n",
    "    \"\"\" Get the data for just one channel (eg, wrist torque)\n",
    "    @param all_data - the my_test_data_XX numpy array\n",
    "    @param start_index - where to start getting data from (should be 0, 1, or 2 for our test data)\n",
    "    @param n_total_dims - what the skip value is - the total number of channels (3 in our case)\n",
    "    @param n_time_steps - number of time steps\n",
    "    @return Return array should be n_rows X n_timesteps\"\"\"\n",
    "\n",
    "    # TODO Your slice code goes here. Note that the input variables match the names in the scratch cell...\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Now check by calling the create data and slice data functions\n",
    "\n",
    "n_samples = 20\n",
    "n_time_steps = 40\n",
    "n_total_dims = 3\n",
    "my_test_data_check_slice = make_xyz_time_data(n_samples=n_samples, n_time_steps=n_time_steps)\n",
    "\n",
    "my_x_slice_check = get_single_channel(my_test_data_check_slice, start_index=0, n_total_dims=n_total_dims, n_time_steps=n_time_steps)\n",
    "my_y_slice_check = get_single_channel(my_test_data_check_slice, start_index=1, n_total_dims=n_total_dims, n_time_steps=n_time_steps)\n",
    "my_z_slice_check = get_single_channel(my_test_data_check_slice, start_index=2, n_total_dims=n_total_dims, n_time_steps=n_time_steps)\n",
    "\n",
    "# TODO: Check that all of the returned slices are 20 x 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# SELF TESTS\n",
    "# TODO: Check that all of the returned slices are 20 x 40\n",
    "\n",
    "# TODO: Check that the x values start at 0 and end at 1 (see checks above for previous question)\n",
    "\n",
    "# TODO: Check that the y values are between -1 and 0\n",
    "\n",
    "# TODO: Check that the z values are between 10 and 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"data_slice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "## Uh oh again, broken functions\n",
    "\n",
    "The following are two pretty common errors when calling functions. Fix them. \n",
    "\n",
    "Note: The Lecture_2_functions.ipynb script has examples of where functions can go wrong..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def get_max(all_data):\n",
    "    \"\"\" Return the maximum of the data\n",
    "    @param all_data - the data\"\"\"\n",
    "    return np.max(my_test_data_check1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# This is how many time steps we used for my_test_data_check3; should be 15\n",
    "n_time_steps = my_test_data_check3.shape[1] // 3\n",
    "\n",
    "# This line should be fine - should return a 10x15 array\n",
    "x_slice_check3_test = get_single_channel(my_test_data_check3, start_index=0, n_total_dims=3, n_time_steps=n_time_steps)\n",
    "\n",
    "# This line is broken - remember that my_test_data_check3 was created with x values that went from 10 to 100. So this should\n",
    "#   return 100. Why doesn't it? What is it returning? \n",
    "# HINT: double check which array get_max is finding the max of. \n",
    "max_time_step = get_max(x_slice_check3_test)\n",
    "\n",
    "assert np.isclose(max_time_step, 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create the data\n",
    "#   5 samples and 10 time steps\n",
    "my_test_data_check4 = make_xyz_time_data(10, 5)\n",
    "\n",
    "# Get the data back out\n",
    "x_slice_check4 = get_single_channel(my_test_data_check4, 0, 3, 10)\n",
    "\n",
    "# These check works - data starts at 0 and ends at 1\n",
    "assert np.isclose(x_slice_check4[0, 0], 0.0)\n",
    "assert np.isclose(x_slice_check4[0, -1], 1.0)\n",
    "\n",
    "# This one doesn't - the data should be 5x10. Why isn't it?\n",
    "assert x_slice_check4.shape == (5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"fix it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Hours and collaborators\n",
    "Required for every assignment - fill out before you hand-in.\n",
    "\n",
    "Listing names and websites helps you to document who you worked with and what internet help you received in the case of any plagiarism issues. You should list names of anyone (in class or not) who has substantially helped you with an assignment - or anyone you have *helped*. You do not need to list TAs.\n",
    "\n",
    "Listing hours helps us track if the assignments are too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# List of names (creates a set)\n",
    "worked_with_names = {\"not filled out\"}\n",
    "# List of URLS 2U5 (creates a set)\n",
    "websites = {\"not filled out\"}\n",
    "# Approximate number of hours, including lab/in-class time\n",
    "hours = -1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"hours_collaborators\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To submit\n",
    "\n",
    "- Do a restart then run all to make sure everything runs ok\n",
    "-  Repeat: Do a restart, run all, save, and THEN turn in\n",
    "- Save the file (no black dot to the right of the filename)\n",
    "- Submit just this .ipynb file through gradescope, Lecture activity 2, functions\n",
    "- You do NOT need to submit the data files - we will supply those\n",
    "\n",
    "If the Gradescope autograder fails, please check here first for common reasons for it to fail\n",
    "    https://docs.google.com/presentation/d/1tYa5oycUiG4YhXUq5vHvPOpWJ4k_xUPp2rUNIL7Q9RI/edit?usp=sharing\n",
    "\n",
    "Most likely failure for this assignment is not naming the data directory and files correctly; capitalization matters for the Gradescope grader. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "create_data_function": {
     "name": "create_data_function",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert my_test_data_check1.shape[0] == 5\n>>> assert my_test_data_check1.shape[1] == 10 * 3 + 1\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert my_test_data_check2.shape[0] == 7\n>>> assert my_test_data_check2.shape[1] == 13 * 3 + 1\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.all(np.isclose(my_test_data_check3[:, 0], 10.0))\n>>> assert np.all(np.isclose(my_test_data_check3[:, -4], 100.0))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.all(my_test_data_check3[:, 1:-1:3] >= -1.0)\n>>> assert np.all(my_test_data_check3[:, 1:-1:3] <= 2.0)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.all(my_test_data_check3[:, 2:-1:3] >= 1.0)\n>>> assert np.all(my_test_data_check3[:, 2:-1:3] <= 3.0)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.all(np.isclose(my_test_data_check3[:, -1], 0.0) | np.isclose(my_test_data_check3[:, -1], 1.0))\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "data_slice": {
     "name": "data_slice",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert my_x_slice_check.shape == (20, 40)\n>>> assert my_y_slice_check.shape == (20, 40)\n>>> assert my_z_slice_check.shape == (20, 40)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.all(np.isclose(my_x_slice_check[:, 0], 0.0))\n>>> assert np.all(np.isclose(my_x_slice_check[:, -1], 1.0))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.all(my_y_slice_check <= 0.0)\n>>> assert np.all(my_y_slice_check >= -1.0)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.all(my_z_slice_check <= 20.0)\n>>> assert np.all(my_z_slice_check >= 10.0)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "fix it": {
     "name": "fix it",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert np.isclose(max_time_step, 100.0)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert x_slice_check4.shape == (5, 10)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "hours_collaborators": {
     "name": "hours_collaborators",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not 'not filled out' in worked_with_names\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert not 'not filled out' in websites\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert hours > 0\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "list": {
     "name": "list",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> res = calc_stats_from_list([-1, 2, -3, 4, -5])\n>>> assert np.isclose(res['Mean positive'], 3.0)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> res = calc_stats_from_list([-1, 2, -3, 4, -5])\n>>> assert np.isclose(res['Mean negative'], -3.0)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> res = calc_stats_from_list([-1, 2, -3, 4, -5])\n>>> assert np.isclose(res['Count positive'], 2)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> res = calc_stats_from_list([-1, 2, -3, 4, -5])\n>>> assert np.isclose(res['Count negative'], 3)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "nparray": {
     "name": "nparray",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> test_data = np.array([-1, 2, -3, 4, -5])\n>>> res = calc_stats_from_nparray(test_data)\n>>> assert np.isclose(res['Mean positive'], 3.0)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> test_data = np.array([-1, 2, -3, 4, -5])\n>>> res = calc_stats_from_nparray(test_data)\n>>> assert np.isclose(res['Mean negative'], -3.0)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> test_data = np.array([-1, 2, -3, 4, -5])\n>>> res = calc_stats_from_nparray(test_data)\n>>> assert np.isclose(res['Count positive'], 2)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> test_data = np.array([-1, 2, -3, 4, -5])\n>>> res = calc_stats_from_nparray(test_data)\n>>> assert np.isclose(res['Count negative'], 3)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
